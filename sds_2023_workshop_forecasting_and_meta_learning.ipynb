{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XGnMvWUwnvgD"
      },
      "source": [
        "# SDS 2023 Forecasting & Meta Learning Workshop\n",
        "\n",
        "In this notebook, we will get our hands dirty with Darts. We will do the following things:\n",
        "\n",
        "* **Part 1:** Forecasting passenger counts series for 300 airlines (`air` dataset). We will train one model per series.\n",
        "* **Part 2:** Using \"global\" models - i.e., models trained on all 300 series simultaneously. Here we split every timeseries into data from the trainset and data from the testset.\n",
        "* **Part 3:** We will try some *meta learning*, and see what happens if we train some global models on one (big) dataset (`m4` dataset) and use them on another dataset. Compared to part 2, m4 is the trainset and m3 will be our testset.\n",
        "* **Part 4:** We will reuse our pre-trained model(s) of Part 3 on another new dataset (`m3` dataset) and see how it compares to models specifically trained on this dataset.\n",
        "\n",
        "## Part 0: Setup (No code to write - execute only)\n",
        "First, we need to install the right libraries and make the right imports. For the deep learning models, it will help to use a GPU runtime. To get a GPU instance, click on the \"RAM/Disk\" info bars on the upper right, select \"Change runtime type\" and choose a GPU as hardware accelerator. The following command will show you the GPU available (if any). If there's no GPU available, you can still go ahead and work on CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pP-5QufS7hM"
      },
      "outputs": [],
      "source": [
        "# You can run this command to see if there's a GPU:\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JXsclCdygxH"
      },
      "outputs": [],
      "source": [
        "!pip install -q darts matplotlib seaborn tqdm sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ha0yFbPzGt_"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "import tqdm.notebook as tq\n",
        "from datetime import datetime\n",
        "import torch\n",
        "from torch import nn\n",
        "from typing import List, Tuple, Dict\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.utils.losses import SmapeLoss\n",
        "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
        "from darts.metrics import smape, mase, mape\n",
        "from darts.utils.data import HorizonBasedDataset\n",
        "from darts.utils.utils import SeasonalityMode, TrendMode, ModelMode\n",
        "from darts.models import (\n",
        "    NaiveSeasonal, NBEATSModel, ExponentialSmoothing,\n",
        "    TCNModel, RegressionModel, LinearRegressionModel,\n",
        "    LightGBMModel, ARIMA, Theta, KalmanForecaster\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kUUcOuC43zF7"
      },
      "source": [
        "We define the forecast horizon here - for all of the (monthly) time series used in this notebook, we'll be interested in forecasting 18 months in advance. We pick 18 months as this is what is used in the M3/M4 competitions for monthly series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPpceDS837z2"
      },
      "outputs": [],
      "source": [
        "HORIZON = 18"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p3L8CEK-ZXV5"
      },
      "source": [
        "### Datasets loading methods\n",
        "Here, we define some helper methods to load the three datasets we'll be playing with: `air`, `m3` and `m4`.\n",
        "\n",
        "All the methods below return two list of `TimeSeries`: one list of training series and one list of \"test\" series (of length `HORIZON`).\n",
        "\n",
        "For convenience, all the series are already scaled here, by multiplying each of them by a constant so that the largest value is 1. Such scaling is necessary for many models to work correctly (esp. deep learning models). It does not affect the sMAPE values, so we can evaluate the accuracy of our algorithms on the scaled series. In a real application, we would have to keep the Darts `Scaler` objects somewhere in order to inverse-scale the forecasts (more in [this section of the documentation](https://unit8co.github.io/darts/generated_api/darts.dataprocessing.transformers.scaler.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSzWi6hwbuQ7",
        "outputId": "bfe22e1f-4b14-405b-8f5b-200b51a723f6"
      },
      "outputs": [],
      "source": [
        "# Execute this cell once to download all three datasets\n",
        "!curl -L https://github.com/unit8co/sds2023-forecating-and-meta-learning/blob/main/data/m3_dataset.xls\\?raw\\=true -o m3_dataset.xls\n",
        "!curl -L https://github.com/unit8co/sds2023-forecating-and-meta-learning/blob/main/data/passengers_per_carrier.csv\\?raw\\=true -o passengers_per_carrier.csv\n",
        "!curl -L https://github.com/unit8co/sds2023-forecating-and-meta-learning/blob/main/data/m4_monthly_scaled.pkl\\?raw\\=true -o m4_monthly_scaled.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNWjOs-_Z0zD"
      },
      "outputs": [],
      "source": [
        "def load_m3() -> Tuple[List[TimeSeries], List[TimeSeries]]:\n",
        "    print('building M3 TimeSeries...')\n",
        "\n",
        "    # Read DataFrame\n",
        "    df_m3 = (pd.read_excel('m3_dataset.xls', 'M3Month'))\n",
        "\n",
        "    # Build TimeSeries\n",
        "    m3_series = []\n",
        "    for row in tq.tqdm(df_m3.iterrows(), position=0, leave=True):\n",
        "        s = row[1]\n",
        "        start_year = int(s['Starting Year'])\n",
        "        start_month = int(s['Starting Month'])\n",
        "        values_series = s[6:].dropna()\n",
        "        if start_month == 0:\n",
        "            continue\n",
        "\n",
        "        start_date = datetime(year=start_year, month=start_month, day=1)\n",
        "        time_axis = pd.date_range(start_date, periods=len(values_series))\n",
        "        series = TimeSeries.from_times_and_values(time_axis, values_series.values).astype(np.float32)\n",
        "        m3_series.append(series)\n",
        "\n",
        "    print('\\nThere are {} monthly series in the M3 dataset'.format(len(m3_series)))\n",
        "\n",
        "    # Split train/test\n",
        "    print('splitting train/test...')\n",
        "    m3_train = [s[:-HORIZON] for s in m3_series]\n",
        "    m3_test = [s[-HORIZON:] for s in m3_series]\n",
        "\n",
        "    # Scale so that the largest value is 1\n",
        "    print('scaling...')\n",
        "    scaler_m3 = Scaler(scaler=MaxAbsScaler())\n",
        "    m3_train_scaled: List[TimeSeries] = scaler_m3.fit_transform(m3_train)\n",
        "    m3_test_scaled: List[TimeSeries] = scaler_m3.transform(m3_test)\n",
        "\n",
        "    print('done. There are {} series, with average training length {}'.format(\n",
        "        len(m3_train_scaled), np.mean([len(s) for s in m3_train_scaled])\n",
        "    ))\n",
        "    return m3_train_scaled, m3_test_scaled\n",
        "\n",
        "def load_air() -> Tuple[List[TimeSeries], List[TimeSeries]]:\n",
        "    df_per_carrier = pd.read_csv(\"/content/passengers_per_carrier.csv\", dtype={\"passengers\": np.float32})\n",
        "    df_per_carrier[\"month\"] = df_per_carrier[\"month\"].apply(pd.to_datetime)\n",
        "    # Passenger filtering\n",
        "    carriers_total_passenger = df_per_carrier.groupby(\"carrier_name\").agg(total_passengers = (\"passengers\", \"sum\"))\n",
        "    CARRIERS_TO_KEEP = carriers_total_passenger.query(\"total_passengers > 100000\").index.values.tolist()\n",
        "    df_per_carrier_filt = (\n",
        "        df_per_carrier\n",
        "        .query(\"carrier_name in @CARRIERS_TO_KEEP\")\n",
        "    )\n",
        "    df_per_carrier_filt = df_per_carrier_filt.loc[:, [\"carrier_name\", \"passengers\", \"month\"]]\n",
        "    min_len = 60\n",
        "    air_data = TimeSeries.from_group_dataframe(df_per_carrier_filt, group_cols=\"carrier_name\", value_cols=\"passengers\", time_col=\"month\", freq=\"MS\")\n",
        "    # Filtering\n",
        "    air_data = [a for a in air_data if len(a) > min_len and a.min(axis=0).values() > 0]\n",
        "    # Interpolating\n",
        "    transformer = MissingValuesFiller()\n",
        "    air_data = [transformer.transform(a) for a in air_data]\n",
        "    # Train test\n",
        "    air_train, air_test = [a[:-HORIZON] for a in air_data], [a[-HORIZON:] for a in air_data]\n",
        "    # Rescaling between 0 and 1\n",
        "    scaler_air = Scaler(scaler=MaxAbsScaler())\n",
        "    air_train = scaler_air.fit_transform(air_train)\n",
        "    air_test = scaler_air.transform(air_test)\n",
        "    print('done. There are {} series, with average training length {}'.format(\n",
        "          len(air_train), np.mean([len(s) for s in air_train])\n",
        "      ))\n",
        "    return air_train, air_test\n",
        "\n",
        "def load_m4() -> Tuple[List[TimeSeries], List[TimeSeries]]:\n",
        "    # load TimeSeries - the splitting and scaling has already been done\n",
        "    print('loading M4 TimeSeries...')\n",
        "    with open('m4_monthly_scaled.pkl', 'rb') as f:\n",
        "        m4_series = pickle.load(f)\n",
        "    m4_train_scaled, m4_test_scaled = zip(*m4_series)\n",
        "\n",
        "    print('done. There are {} series, with average training length {}'.format(\n",
        "        len(m4_train_scaled), np.mean([len(s) for s in m4_train_scaled])\n",
        "    ))\n",
        "    return m4_train_scaled, m4_test_scaled"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "co-uraewuSmu"
      },
      "source": [
        "Finally, we define a handy function to tell us how good a bunch of forecasted series are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzVPxA0fuZn_"
      },
      "outputs": [],
      "source": [
        "def eval_forecasts(pred_series: List[TimeSeries],\n",
        "                   test_series: List[TimeSeries]) -> List[float]:\n",
        "\n",
        "    print('computing sMAPEs...')\n",
        "    smapes = smape(test_series, pred_series)\n",
        "    mean, std = np.mean(smapes), np.std(smapes)\n",
        "    print('Avg sMAPE: %.3f +- %.3f' % (mean, std))\n",
        "    plt.figure(figsize=(4,4), dpi=144)\n",
        "    plt.hist(smapes, bins=50)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('sMAPE')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    return smapes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T6VEn8bJcu1p"
      },
      "source": [
        "## Part 1: Local models on the `air` dataset\n",
        "\n",
        "The `air` dataset shows the number of air passengers that flew in or out of the USA per carrier (or airline company) from the year 2000 until 2019.\n",
        "\n",
        "**Your turn:** First, you can load the train and test series by calling `load_air()` function that we have defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EBtqxQ4yFkC",
        "outputId": "16e6eda8-3dd5-4d44-ed9c-41ccf904e378"
      },
      "outputs": [],
      "source": [
        "air_train, air_test = ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgy20GU_6xjn"
      },
      "source": [
        "It's a good idea to start by visualising a few of the series to get a sense of what they look like. We can plot a series by calling `series.plot()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQTDjvDFcNeY"
      },
      "outputs": [],
      "source": [
        "for i in [1, 20, 50, 100, 125]:\n",
        "    plt.figure(figsize=(4,4), dpi=144)\n",
        "    air_train[i].plot(label=air_train[i].static_covariates.loc[\"passengers\", \"carrier_name\"])\n",
        "    plt.ylabel('Passengers')\n",
        "    plt.xlabel('Time')\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fTw4PlKf60Cw"
      },
      "source": [
        "We can see that most series look quite different, and they even have different time axes.\n",
        "\n",
        "**Question:** What is the smallest series available?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw0ZLbcQ5lCi"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X_RuW13DrNbo"
      },
      "source": [
        "### Forecasting with a first (very) naive model\n",
        "\n",
        "We can now try a first forecasting model on this dataset. As a first step, it is usually a good practice to see how a (very) naive model blindly repeating the last value of the training series performs. This can be done in Darts using a [NaiveSeasonal](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.baselines.html#darts.models.forecasting.baselines.NaiveSeasonal) model.\n",
        "\n",
        "**Your turn:** Try forecasting a few time series of the air dataset using the `NaiveSeasonal` model. You can use the function `eval_forecasts` defined above to evaluate the forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX19O1t6rGLs"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtt4M98dg9e9"
      },
      "source": [
        "### A useful function to evaluate models\n",
        "\n",
        "Below, we write a small function that will make our life easier for quickly trying and comparing different local models. We loop through each serie, fit a model and then evaluate on our test dataset.\n",
        "\n",
        "> ⚠️ Please note `tq.tqdm` is optional and is only there to help display the training progress (as you will see, depending on the model, it can take some time when training 300+ time series)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9HLgVQkg36Z"
      },
      "outputs": [],
      "source": [
        "def eval_local_model(train_series: List[TimeSeries],\n",
        "                     test_series: List[TimeSeries],\n",
        "                     model_cls,\n",
        "                     **kwargs) -> Tuple[List[float], float]:\n",
        "    preds = []\n",
        "    start_time = time.time()\n",
        "    for series in tq.tqdm(train_series):\n",
        "        model = model_cls(**kwargs)\n",
        "        model.fit(series)\n",
        "        pred = model.predict(n=HORIZON)\n",
        "        preds.append(pred)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    smapes = eval_forecasts(preds, test_series)\n",
        "    return smapes, elapsed_time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QUTMqfh1ht3I"
      },
      "source": [
        "We can apply this function to fit all the time series of the dataset with the `NaiveSeasonal` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616,
          "referenced_widgets": [
            "6d414cbe3fc244ee9d051ea5a2903ea3",
            "7f6650d420204ef391d037de627192d8",
            "0c5340e027894630be4c21055cd996d6",
            "a604595cccb5422e95b8566575b34e9e",
            "b6020e3f908b46a182c6e4b352452c51",
            "9462bf36036e46f086b81ee1ed374338",
            "4f6c49fac6e2443d938b8e0fa591bda3",
            "468876b6206e41a9b8997da90678e55d",
            "1bbf1be74d3b4c0ca077cf70f6447c9a",
            "f8fb46b03b754613b1c01e36b52719ab",
            "004ab8ba4b764451bf6164687f554b6f"
          ]
        },
        "id": "pIo0vIK-g4FS",
        "outputId": "61ddb6bd-2bea-44ff-f39b-7052bf5545e0"
      },
      "outputs": [],
      "source": [
        "naive_seasonal_last_smapes, naive_seasonal_last_elapsed_time  = eval_local_model(air_train, air_test, NaiveSeasonal, K=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "791lysIiyokK"
      },
      "source": [
        "So the most naive model gives us an average sMAPE of about 26.42.\n",
        "\n",
        "**Your turn:** Can we do better with a \"less naive\" model exploiting the fact that most monthly series have a seasonality of 12?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhVv0I0jzKrQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "npMWQw9FzMy6"
      },
      "source": [
        "All of the Darts forecasting models can be trained and used in the same way!\n",
        "So we invite you to go over the [list of models in the API documentation](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.html) and try a few more models. Here are some suggestions:\n",
        "\n",
        "* `ExponentialSmoothing`\n",
        "* `Theta`\n",
        "* `ARIMA` - but the default parameters probably won't do very well. Using `p=12`, `d=1`, `q=0` might be a good start.\n",
        "* ... Your ideas here!\n",
        "\n",
        "We recommend that you keep track of the SMAPEs and elapsed times for each model. Later we will use these values for quickly comparing models. Some models will take longer than others to run. Don't hesitate to interrupt the execution or run only on a subset of series.\n",
        "\n",
        "**Your turn:** Try to get the lowest possible errors with some other models of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVUmdNBU19Q-"
      },
      "outputs": [],
      "source": [
        "# model_X_smapes, model_X_elapsed_time = eval_local_model(air_train, air_test, ModelX, **hyper_params_for_model_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRSVc9pPCJi"
      },
      "source": [
        "### Comparing models\n",
        "\n",
        "Below, we define a couple of functions that we will use to obtain an overview of the SMAPEs and time required to obtain the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBy5eqrpFhZP"
      },
      "outputs": [],
      "source": [
        "def smapes_boxplot(method_to_smapes: Dict[str, List[float]], title: str):\n",
        "  method_names = []\n",
        "  smapes = []\n",
        "  for curr_method_name, curr_smapes in method_to_smapes.items():\n",
        "    method_names += [curr_method_name] * len(curr_smapes)\n",
        "    smapes += curr_smapes\n",
        "  smapes_df = pd.DataFrame({'Method': method_names, 'sMAPE': smapes})\n",
        "  plt.figure(figsize=(7,4), dpi=144)\n",
        "  ax = sns.boxplot(x=\"Method\", y=\"sMAPE\", data=smapes_df)\n",
        "  ax.grid(False)\n",
        "  # Display median score on each box\n",
        "  medians = smapes_df.groupby(['Method'])['sMAPE'].median().round(decimals=2)\n",
        "  vertical_offset = smapes_df['sMAPE'].median() * 0.1\n",
        "  for xtick, name in enumerate(method_to_smapes.keys()):\n",
        "    ax.text(xtick, medians[name] + vertical_offset, medians[name],\n",
        "                  horizontalalignment='center', size='x-small', color='w', weight='semibold')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def elapsed_time_barplot(method_to_elapsed_times: Dict[str, float], title: str):\n",
        "  elapsed_times_df = pd.DataFrame({'Method': method_to_elapsed_times.keys(), 'Elapsed time [s]': method_to_elapsed_times.values()})\n",
        "  ax = plt.figure(figsize=(7,4), dpi=144)\n",
        "  sns.barplot(x=\"Method\", y=\"Elapsed time [s]\", data=elapsed_times_df)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "  plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hlPzIxjm2XgI"
      },
      "source": [
        "**Your turn:** We are now ready to visualise our models. Fill in the cells below to call `smapes_boxplot()` and `elpased_time_barplot()` with the right arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgnHS7mf-_0r"
      },
      "outputs": [],
      "source": [
        "smapes = {\n",
        "    'NaiveSeasonal last': naive_seasonal_last_smapes,\n",
        "    # 'model_X': model_X_smapes,\n",
        "    # ...\n",
        "}\n",
        "smapes_boxplot(smapes, title='sMAPEs on air')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olnp0bVJFecR"
      },
      "outputs": [],
      "source": [
        "elapsed_times = {\n",
        "    'NaiveSeasonal last': naive_seasonal_last_elapsed_time,\n",
        "    # 'model_X': model_X_elapsed_time,\n",
        "    # ...\n",
        "}\n",
        "elapsed_time_barplot(elapsed_times, title='Duration on air')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nS4NuMjdrjRL"
      },
      "source": [
        "### Conclusions so far:\n",
        "You can also try to directly predict some of the forecasts in order to visualise them.\n",
        "\n",
        "What are your conclusions so far?\n",
        "\n",
        "What are your best forecasts? Let us know!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K-udVZtF3DDp"
      },
      "source": [
        "## Part 2: Global models on the `air` dataset\n",
        "In this section we will use \"global models\" - that is, models that fit on multiple series at once (more information in [this section of the documentation](https://unit8co.github.io/darts/quickstart/00-quickstart.html#Machine-learning-and-global-models)). Darts has essentially two kinds of global models:\n",
        "* `RegressionModels` which are wrappers around sklearn-like regression models (Part 2.1).\n",
        "* PyTorch-based models, which offer various deep learning models (Part 2.2).\n",
        "\n",
        "Both models can be trained on multiple series by \"tabularizing\" the data - i.e., taking many (input, output) sub-slices from all the training series, and training machine learning models in a supervised fashion to predict the output based on the input ([more details here](https://unit8co.github.io/darts/userguide/torch_forecasting_models.html#in-depth-look-at-how-input-data-is-used-when-training-and-predicting-with-tfms)).\n",
        "\n",
        "**Your turn** We will start by defining a function `eval_global_model()` which works similarly to `eval_local_model()`, but on global models. You can complete it below (hint: you will not need the for-loop that was present in `eval_local_model()`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geFFgHCo3P8Z"
      },
      "outputs": [],
      "source": [
        "def eval_global_model(train_series: List[TimeSeries],\n",
        "                      test_series: List[TimeSeries],\n",
        "                      model_cls,\n",
        "                      **kwargs) -> Tuple[List[float], float]:\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # build your model here\n",
        "    ...\n",
        "\n",
        "    # fit your model here\n",
        "    ...\n",
        "\n",
        "    # get some predictions here\n",
        "    preds = ...\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    smapes = eval_forecasts(preds, test_series)\n",
        "    return smapes, elapsed_time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ohc7H1P3mx2"
      },
      "source": [
        "### Part 2.1: Using Darts `RegressionModel`s.\n",
        "`RegressionModel` in Darts are forecasting models that can wrap around any \"scikit-learn compatible\" regression model to obtain forecasts. Compared to deep learning, they represent good \"go-to\" global models because they typically don't have many hyper-parameters and can be faster to train. In addition, Darts also offers some \"pre-packaged\" regression models such as `LinearRegressionModel` and `LightGBMModel`.\n",
        "\n",
        "We'll now use our function `eval_global_models()`. In the following cells, you can try using some regression models, for example:\n",
        "* `LinearRegressionModel`\n",
        "* `LightGBMModel`\n",
        "* `RegressionModel`(your_sklearn_model)\n",
        "\n",
        "You can refer to [the API doc](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.regression_model.html) for how to use them.\n",
        "\n",
        "Important parameters are `lags` and `output_chunk_length`. They determine respectively the length of the lookback and \"lookforward\" windows used by the model, and they correspond to the lengths of the input/output subslices used for training. For instance `lags=34` and `output_chunk_length=12` mean that the model will consume the past 34 lags in order to predict the next 12. In our case, because the shortest training series has length 46, we must have `lags + output_chunk_length <= 46`. (Note that `lags` can also be a list of integers representing the individual lags to be consumed by the model instead of the window length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaGYbfI43oug"
      },
      "outputs": [],
      "source": [
        "# model_X_smapes, model_X_elapsed_time = eval_global_model(air_train, air_test, GlobalModelX, **hyper_params_for_model_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zMxzNto5spdc"
      },
      "source": [
        "### Part 2.2: Using deep learning\n",
        "Below, we will train an N-BEATS model on our `air` dataset. Again, you can refer to [the API doc](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.nbeats.html) for documentation on the hyper-parameters.\n",
        "The following hyper-parameters should be a good starting point, and training should take in the order of a minute or two.\n",
        "\n",
        "During training, you can have a look at the [N-BEATS paper](https://arxiv.org/abs/1905.10437)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZDirbwpsoF-"
      },
      "outputs": [],
      "source": [
        "# Slicing hyper-params:\n",
        "IN_LEN = 24\n",
        "OUT_LEN = 12\n",
        "\n",
        "# Architecture hyper-params:\n",
        "NUM_STACKS = 18\n",
        "NUM_BLOCKS = 3\n",
        "NUM_LAYERS = 3\n",
        "LAYER_WIDTH = 180\n",
        "COEFFS_DIM = 6\n",
        "LOSS_FN = SmapeLoss()\n",
        "\n",
        "# Training settings:\n",
        "LR = 5e-4\n",
        "BATCH_SIZE = 1024\n",
        "NUM_EPOCHS = 4"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VSrYcr9K4tE_"
      },
      "source": [
        "You can now complete the skeleton below to build, train and predict using an N-BEATS model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Yy85Z7tsoKF"
      },
      "outputs": [],
      "source": [
        "# reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "## Use this to specify \"optimizer_kwargs\" parameter of the N-BEATS model:\n",
        "optimizer_kwargs={'lr': LR},\n",
        "\n",
        "## In addition, when using a GPU, you should specify this for\n",
        "## the \"pl_trainer_kwargs\" parameter of the N-BEATS model:\n",
        "pl_trainer_kwargs={\"enable_progress_bar\": True,\n",
        "                   \"accelerator\": \"gpu\",\n",
        "                   \"gpus\": -1,\n",
        "                   \"auto_select_gpus\": True}\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "nbeats_model_air = ... # Build the N-BEATS model here\n",
        "\n",
        "nbeats_model_air.fit(..., # fill in series to train on\n",
        "                     ...) # fill in number of epochs\n",
        "\n",
        "# get predictions\n",
        "nb_preds = ...\n",
        "\n",
        "nbeats_smapes = eval_forecasts(nb_preds, air_test)\n",
        "nbeats_elapsed_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWipgclvfKel"
      },
      "outputs": [],
      "source": [
        "smapes_2 = smapes | {\n",
        "    # ... Fill in here sMAPEs values of any global model you tried\n",
        "    'NBeats': nbeats_smapes,\n",
        "  }\n",
        "\n",
        "smapes_boxplot(smapes_2, title='sMAPEs on air')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8Gi53et6P_e"
      },
      "outputs": [],
      "source": [
        "elapsed_time_2 = elapsed_times | {\n",
        "    # ... Fill in here duration values of any global model you tried\n",
        "    'NBeats': nbeats_elapsed_time,\n",
        "}\n",
        "elapsed_time_barplot(elapsed_time_2, title='Durations on air')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vCzqR2xQzrAr"
      },
      "source": [
        "What are your conclusions so far, and which results did you manage to get (let us know!)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TxI9CLZc6Y5g"
      },
      "source": [
        "## Part 3: Training an N-BEATS model on `m4` dataset and use it to forecast `air` dataset\n",
        "Deep learning models often do better when trained on *large* datasets. Let's try to load all 48,000 monthly time series in the M4 dataset and train our model once more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn3p5nat1aip"
      },
      "outputs": [],
      "source": [
        "m4_train, m4_test = load_m4()\n",
        "\n",
        "# filter to keep only those that are long enough\n",
        "filtered = filter(lambda t: len(t[0]) >= 48, zip(m4_train, m4_test))\n",
        "m4_train, m4_test = zip(*filtered)\n",
        "m4_train, m4_test = list(m4_train), list(m4_test)\n",
        "\n",
        "print('There are {} series of length >= 48.'.format(len(m4_train)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ84E__e1vfQ"
      },
      "source": [
        "We can start from the same hyper-parameters as before.\n",
        "\n",
        "With 48,000 M4 training series being on average ~200 time steps long, we would end up with ~10M training samples. With such a number of training samples, each epoch would take too long. So here, we'll limit the number of training samples used per series. This is done when calling `fit()` with the parameter `max_samples_per_ts`. We add a new hyper-parameter `MAX_SAMPLES_PER_TS` to capture this.\n",
        "\n",
        "Since the M4 training series are all >= 48 time steps long, we can also use a slightly longer `input_chunk_length` of 36."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zyOtrjGreEo"
      },
      "outputs": [],
      "source": [
        "# Slicing hyper-params:\n",
        "IN_LEN = 36\n",
        "OUT_LEN = 12\n",
        "\n",
        "# Architecture hyper-params:\n",
        "NUM_STACKS = 18\n",
        "NUM_BLOCKS = 3\n",
        "NUM_LAYERS = 3\n",
        "LAYER_WIDTH = 180\n",
        "COEFFS_DIM = 6\n",
        "LOSS_FN = SmapeLoss()\n",
        "\n",
        "# Training settings:\n",
        "LR = 5e-4\n",
        "BATCH_SIZE = 1024\n",
        "MAX_SAMPLES_PER_TS = 8   # <-- new param, limiting nr of training samples per epoch\n",
        "NUM_EPOCHS = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRgxs08greJE"
      },
      "outputs": [],
      "source": [
        "# reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "nbeats_model_m4 = NBEATSModel(..., # fill in hyper-params\n",
        "\n",
        "                              # Don't forget to set the \"pl_trainer_kwargs\" parameter\n",
        "                              # if your notebook has a GPU\n",
        "                              pl_trainer_kwargs=...\n",
        "                              )\n",
        "\n",
        "# Train\n",
        "nbeats_model_m4.fit(..., # fill in series to train on\n",
        "                    ..., # fill in number of epochs\n",
        "                    ...) # fill in max number of samples per time series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72jubSWvqxoJ"
      },
      "outputs": [],
      "source": [
        "## /!\\ RUNNING THIS CELL WILL DOWNLOAD AND OVERWRITE THE MODEL nbeats_model_m4\n",
        "\n",
        "# # Load already trained model\n",
        "# # !curl -L https://github.com/unit8co/sds2023-forecasting-and-meta-learning/blob/main/data/nbeats_pretrained_model_m4.zip\\?raw\\=true -o nbeats_pretrained_model_m4.zip\n",
        "# with zipfile.ZipFile(\"nbeats_pretrained_model_m4.zip\",\"r\") as zip_ref:\n",
        "#     zip_ref.extractall(\"/content/\")\n",
        "# nbeats_model_m4 = NBEATSModel.load(\"nbeats/NBEATSModel.pt\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2NEENoGK763V"
      },
      "source": [
        "We can now use our M4-trained model to get forecasts for the air passengers series. As we use the model in a \"meta learning\" (or transfer learning) way here, we will be timing only the inference part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S2esxXzreNW"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "preds = ... # get forecasts\n",
        "nbeats_m4_smapes = eval_forecasts(preds, air_test)\n",
        "nbeats_m4_elapsed_time = time.time() - start_time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sV2PDSrkpVXf"
      },
      "source": [
        "What are your conclusions?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_GLmcD8KnC"
      },
      "source": [
        "### Try training other global models on `m4` and applying on airline passengers\n",
        "You can now try to train other global models on the M4 dataset in order to see if we can get similar results. If that's taking too long, it might be a good idea to take only e.g., 5'000 or 10'000 time series. You can do this easily by training on, say, `random.choices(m4_train, k=5000)` instead of `m4_train`. You will again need to specify some small enough value for `max_samples_per_ts` in order to limit the number of training samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPrjayclreQd"
      },
      "outputs": [],
      "source": [
        "# reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# model_X = GlobalModelX(...)\n",
        "# model_X.fit(...,\n",
        "#             max_samples_per_ts=...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HosI0UZKpwSx"
      },
      "outputs": [],
      "source": [
        "# start_time = time.time()\n",
        "# preds = ...  # Get predictions\n",
        "# model_X_smapes = eval_forecasts(preds, air_test)  # compute errors\n",
        "# model_X_elapsed_time = time.time() - start_time  # store timing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVFumYDjiGEZ"
      },
      "outputs": [],
      "source": [
        "smapes_3 = smapes_2 | {\n",
        "    'NBeats M4': nbeats_m4_smapes,\n",
        "    # 'model_X': model_X_smapes\n",
        "    # ...\n",
        "}\n",
        "smapes_boxplot(smapes_3, title='sMAPEs on air')\n",
        "\n",
        "elapsed_time_3 = elapsed_time_2 | {\n",
        "    'NBeats M4': nbeats_m4_elapsed_time,\n",
        "    # 'model_X': model_X_elapsed_time\n",
        "    # ...\n",
        "}\n",
        "elapsed_time_barplot(elapsed_time_3, title='Durations on air')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gtkyiQ_OvUNz"
      },
      "source": [
        "## Part 4: Forecasting the `m3` dataset\n",
        "\n",
        "Until now, we have seen that we can use some M4-trained models to predict another dataset, namely the `air` dataset.\n",
        "But can we try to convince ourselves a bit more, and try the same approach on a third dataset?\n",
        "\n",
        "In this part of the notebook, we propose to consolidate all our learnings so far using the `m3` dataset:\n",
        "* Try fitting local models directly on `m3`\n",
        "* Try fitting global ML models directly on `m3` --> how far can you push it?\n",
        "* Try applying our previous M4-trained model on `m3` --> what are your conclusions?\n",
        "\n",
        "Hint: The Theta model was one of the best performing model during the M3 competition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "328ca581c9e9407e98138cb7aca0d8f6",
            "5321fff544db4fe5be665620ce4808f3",
            "5fdc604f906d4d3eb80ecf59d08a196b",
            "b4849be5f40a4336b748b521346878a4",
            "fd13277aaa994bd3a59930480358ecbf",
            "80bf41358ee54300b69171cd1e7e9266",
            "a5485549e21b4a0b9644bbf941f4fcbd",
            "26fb7f247526476bbc39929eb11611a4",
            "c8e56152b7734ba79610f3923d37fb2f",
            "1dc3b35c654c46b1ba90a7ca038d0838",
            "8c17978889864505abc9833f618ac6a8"
          ]
        },
        "id": "WGQWwvyHpTaz",
        "outputId": "c2d9894b-9509-47e1-be9f-e3ed247837d6"
      },
      "outputs": [],
      "source": [
        "# First, load the actual dataset\n",
        "m3_train, m3_test = load_m3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN9Q3tEGCte0"
      },
      "outputs": [],
      "source": [
        "# Then try your models :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aPF74IC9MiP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "004ab8ba4b764451bf6164687f554b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c5340e027894630be4c21055cd996d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468876b6206e41a9b8997da90678e55d",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bbf1be74d3b4c0ca077cf70f6447c9a",
            "value": 150
          }
        },
        "1bbf1be74d3b4c0ca077cf70f6447c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dc3b35c654c46b1ba90a7ca038d0838": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26fb7f247526476bbc39929eb11611a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "328ca581c9e9407e98138cb7aca0d8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5321fff544db4fe5be665620ce4808f3",
              "IPY_MODEL_5fdc604f906d4d3eb80ecf59d08a196b",
              "IPY_MODEL_b4849be5f40a4336b748b521346878a4"
            ],
            "layout": "IPY_MODEL_fd13277aaa994bd3a59930480358ecbf"
          }
        },
        "468876b6206e41a9b8997da90678e55d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6c49fac6e2443d938b8e0fa591bda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5321fff544db4fe5be665620ce4808f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80bf41358ee54300b69171cd1e7e9266",
            "placeholder": "​",
            "style": "IPY_MODEL_a5485549e21b4a0b9644bbf941f4fcbd",
            "value": ""
          }
        },
        "5fdc604f906d4d3eb80ecf59d08a196b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26fb7f247526476bbc39929eb11611a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8e56152b7734ba79610f3923d37fb2f",
            "value": 1
          }
        },
        "6d414cbe3fc244ee9d051ea5a2903ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f6650d420204ef391d037de627192d8",
              "IPY_MODEL_0c5340e027894630be4c21055cd996d6",
              "IPY_MODEL_a604595cccb5422e95b8566575b34e9e"
            ],
            "layout": "IPY_MODEL_b6020e3f908b46a182c6e4b352452c51"
          }
        },
        "7f6650d420204ef391d037de627192d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9462bf36036e46f086b81ee1ed374338",
            "placeholder": "​",
            "style": "IPY_MODEL_4f6c49fac6e2443d938b8e0fa591bda3",
            "value": "100%"
          }
        },
        "80bf41358ee54300b69171cd1e7e9266": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c17978889864505abc9833f618ac6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9462bf36036e46f086b81ee1ed374338": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5485549e21b4a0b9644bbf941f4fcbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a604595cccb5422e95b8566575b34e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8fb46b03b754613b1c01e36b52719ab",
            "placeholder": "​",
            "style": "IPY_MODEL_004ab8ba4b764451bf6164687f554b6f",
            "value": " 150/150 [00:00&lt;00:00, 301.11it/s]"
          }
        },
        "b4849be5f40a4336b748b521346878a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc3b35c654c46b1ba90a7ca038d0838",
            "placeholder": "​",
            "style": "IPY_MODEL_8c17978889864505abc9833f618ac6a8",
            "value": " 1428/? [00:06&lt;00:00, 184.50it/s]"
          }
        },
        "b6020e3f908b46a182c6e4b352452c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e56152b7734ba79610f3923d37fb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8fb46b03b754613b1c01e36b52719ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd13277aaa994bd3a59930480358ecbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
